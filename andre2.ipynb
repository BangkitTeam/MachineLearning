{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "output_dir = './split_data'\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat folder untuk split dataset\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "for split in ['train', 'val', 'test']:\n",
    "    (Path(output_dir) / split).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset berhasil dibagi!\n"
     ]
    }
   ],
   "source": [
    "for class_name in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, class_name)  # misal ./data/ada_class\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    # Buat folder untuk masing-masing class di train, val, dan test\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_class_dir = os.path.join(output_dir, split, class_name)\n",
    "        os.makedirs(split_class_dir, exist_ok=True)\n",
    "\n",
    "    # Dapatkan semua file gambar dalam folder class\n",
    "    images = [os.path.join(class_dir, img) for img in os.listdir(class_dir)]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Tentukan jumlah data untuk setiap split\n",
    "    train_count = int(len(images) * train_ratio)\n",
    "    val_count = int(len(images) * val_ratio)\n",
    "    test_count = len(images) - train_count - val_count\n",
    "\n",
    "    # Bagi dataset\n",
    "    train_images = images[:train_count]\n",
    "    val_images = images[train_count:train_count + val_count]\n",
    "    test_images = images[train_count + val_count:]\n",
    "\n",
    "    # Salin gambar ke folder split masing-masing\n",
    "    for img in train_images:\n",
    "        shutil.copy(img, os.path.join(output_dir, 'train', class_name))\n",
    "    for img in val_images:\n",
    "        shutil.copy(img, os.path.join(output_dir, 'val', class_name))\n",
    "    for img in test_images:\n",
    "        shutil.copy(img, os.path.join(output_dir, 'test', class_name))\n",
    "\n",
    "print(\"Dataset berhasil dibagi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './split_data'\n",
    "\n",
    "# Parameter dataset\n",
    "image_size = (150, 150) \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21561 files belonging to 22 classes.\n",
      "Found 3804 files belonging to 22 classes.\n",
      "Found 3849 files belonging to 22 classes.\n",
      "Train Dataset: <BatchDataset element_spec=(TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 22), dtype=tf.float32, name=None))>\n",
      "Validation Dataset: <BatchDataset element_spec=(TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 22), dtype=tf.float32, name=None))>\n",
      "Test Dataset: <BatchDataset element_spec=(TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 22), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=f'{data_dir}/train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',  # Menggunakan one-hot encoding\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=f'{data_dir}/val',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False  # Tidak perlu diacak\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=f'{data_dir}/test',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False  # Tidak perlu diacak\n",
    ")\n",
    "\n",
    "# Periksa struktur dataset\n",
    "print(\"Train Dataset:\", train_dataset)\n",
    "print(\"Validation Dataset:\", val_dataset)\n",
    "print(\"Test Dataset:\", test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_final = train_dataset.cache().shuffle(\n",
    "    1000,\n",
    "    reshuffle_each_iteration=True\n",
    ").prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset_final = val_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset_final = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " random_flip (RandomFlip)    (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " random_rotation (RandomRota  (None, 150, 150, 3)      0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " random_zoom (RandomZoom)    (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " random_translation (RandomT  (None, 150, 150, 3)      0         \n",
      " ranslation)                                                     \n",
      "                                                                 \n",
      " random_brightness (RandomBr  (None, 150, 150, 3)      0         \n",
      " ightness)                                                       \n",
      "                                                                 \n",
      " random_contrast (RandomCont  (None, 150, 150, 3)      0         \n",
      " rast)                                                           \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 147968)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               75760128  \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 34)                17442     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75,872,866\n",
      "Trainable params: 75,871,842\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models = tf.keras.models\n",
    "layers = tf.keras.layers\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(150, 150, 3)),\n",
    "\n",
    "    # Augmentasi yang lebih agresif\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.2, fill_mode=\"nearest\"),\n",
    "    tf.keras.layers.RandomZoom(0.2, fill_mode=\"nearest\"),\n",
    "    tf.keras.layers.RandomTranslation(0.2, 0.2, fill_mode=\"nearest\"),\n",
    "    tf.keras.layers.RandomBrightness(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    # # tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    # tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "    # tf.keras.layers.BatchNormalization()\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    # tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # Dense layers dengan regularisasi yang lebih kuat\n",
    "    tf.keras.layers.Dense(512,),\n",
    "\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    # tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(34, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
